{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "url = \"https://www.tradeupspy.com/skins\"\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "\n",
    "# Configure o Selenium para usar o Firefox\n",
    "browser = webdriver.Firefox(options=options)\n",
    "try:\n",
    "    browser.get(url)\n",
    "    # Usamos o XPath para encontrar o elemento desejado\n",
    "    div_xpath = \"/html/body/app-root/html/body/app-skins/div[4]/div[2]/div[7]\"\n",
    "    #target_div = browser.find_element(By.XPATH, div_xpath)\n",
    "    target_div = WebDriverWait(browser, 10).until(\n",
    "        ec.presence_of_element_located((By.XPATH, div_xpath))\n",
    "    )\n",
    "\n",
    "    div_html = target_div.get_attribute('outerHTML')\n",
    "except TimeoutException:\n",
    "    print(\"I give up...\")\n",
    "finally:\n",
    "    browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_prefix = \"https://www.tradeupspy.com\"\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "\n",
    "def parse_collection(collection_name, collection_url):\n",
    "    url = website_prefix + collection_url\n",
    "    print(f\"Processing: {url}\")\n",
    "    browser = webdriver.Firefox(options=options)\n",
    "    try:    \n",
    "        browser.get(url)\n",
    "\n",
    "        xpath_to_wait = \"/html/body/app-root/html/body/app-skins/div[7]/div[2]\"\n",
    "        stattrak_xpath = \"/html/body/app-root/html/body/app-skins/div[6]/div[2]/div[2]/div/p\"\n",
    "\n",
    "        # We wait for the first skin card to load. This way, hopefully all skin cards have loaded\n",
    "        WebDriverWait(browser, 10).until(\n",
    "            ec.presence_of_element_located((By.XPATH, xpath_to_wait))\n",
    "        )\n",
    "\n",
    "        # We wait for the 'stattrak available' element to load\n",
    "        stattrak_available_p = WebDriverWait(browser, 10).until(\n",
    "            ec.presence_of_element_located((By.XPATH, stattrak_xpath))\n",
    "        )\n",
    "        stattrak_text = stattrak_available_p.text\n",
    "        stattrak_available = False\n",
    "\n",
    "        # Check if the text is \"StatTrak™ unavailable\" or \"StatTrak™ available\"\n",
    "        if stattrak_text == \"StatTrak™ available\":\n",
    "            print(\"StatTrak is available.\")\n",
    "            stattrak_available = True\n",
    "\n",
    "        all_skin_cards_div_xpath = \"/html/body/app-root/html/body/app-skins/div[7]/div[2]\"\n",
    "        all_skin_cards_div = browser.find_element(By.XPATH, all_skin_cards_div_xpath)\n",
    "        div_html = all_skin_cards_div.get_attribute('outerHTML')\n",
    "        divSoup = BeautifulSoup(div_html,'html.parser')\n",
    "\n",
    "        # iterate over all skin cards\n",
    "        for skin_card_div in divSoup.find_all('div', class_=\"skin_card_collection\"):\n",
    "            skin_card_wrapper = skin_card_div.find('div', class_=\"skin_card_wrapper\")\n",
    "\n",
    "            # get skin quality. For example: classified_bg, industrial_bg, etc...\n",
    "            skin_quality = skin_card_wrapper['class'][1]\n",
    "            if skin_quality == 'knife_bg':\n",
    "                # current skin is a knife, so we skip (because knives cant be in tradeups)\n",
    "                continue\n",
    "\n",
    "            # get weapon and skin name\n",
    "            skin_card_div_name = skin_card_wrapper.find('div', class_=\"skin_card_name_container\")\n",
    "            skin_card_div_name_a = skin_card_div_name.find('a', class_=\"skin_card_collection_name\")\n",
    "            # Get the text before and after the <br> tag.\n",
    "            weapon_name = skin_card_div_name_a.find(text=True, recursive=False)  # Text before the <br> tag.\n",
    "            skin_name = skin_card_div_name_a.br.nextSibling  # Text after the <br> tag.\n",
    "\n",
    "            # get url to skin web page\n",
    "            skin_card_div_image = skin_card_wrapper.find('div', class_=\"skin_card_image_container\")\n",
    "            skin_card_div_image_a = skin_card_div_image.find('a', class_=\"skin_card_collection_image_url\")\n",
    "            url = skin_card_div_image_a['href']\n",
    "\n",
    "            # Combine the parts with a separator.\n",
    "            full_skin_name = f\"{weapon_name.strip()} | {skin_name.strip()}\"\n",
    "            parse_skin(collection_name, full_skin_name, skin_quality, url, stattrak_available)\n",
    "    except TimeoutException:\n",
    "        print(\"I give up...\")\n",
    "    finally:\n",
    "        browser.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from entities import Skin\n",
    "from db import create_skin\n",
    "\n",
    "website_prefix = \"https://www.tradeupspy.com\"\n",
    "\n",
    "def wait_for_defined_text(driver, xpath, timeout=10):\n",
    "    def _predicate(drv):\n",
    "        element = drv.find_element(By.XPATH, xpath)\n",
    "        text = element.text.strip()\n",
    "        return text if text.lower() != 'undefined' else False\n",
    "    ignored_exceptions = (NoSuchElementException,StaleElementReferenceException,)\n",
    "    return WebDriverWait(driver, timeout, ignored_exceptions=ignored_exceptions).until(_predicate)\n",
    "\n",
    "def parse_skin(collection_name, skin_name, quality, url, stattrak_available):\n",
    "    \"\"\"\n",
    "    collection_name -> example: \"2018 Inferno\"\n",
    "    skin_name -> example : \"M4A4 | Converter\"\n",
    "    quality -> example : \"classified_bg\"\n",
    "    url -> internal url of the skin\n",
    "    \"\"\"\n",
    "    url = website_prefix + url\n",
    "    print(f\"Processing skin: {url}\")\n",
    "    browser = webdriver.Firefox(options=options)\n",
    "    try:    \n",
    "        browser.get(url)\n",
    "\n",
    "        min_float_xpath = \"/html/body/app-root/html/body/app-skins/div[6]/div[2]/div[2]/div[1]/div/div/p[1]/b\"\n",
    "        max_float_xpath = \"/html/body/app-root/html/body/app-skins/div[6]/div[2]/div[2]/div[1]/div/div/p[2]/b\"\n",
    "        \n",
    "        # Wait until the text of the element is not 'undefined'\n",
    "        min_float_text = wait_for_defined_text(browser, min_float_xpath)\n",
    "        max_float_text = wait_for_defined_text(browser, max_float_xpath)\n",
    "    \n",
    "        # Now that we have the texts and they are not 'undefined', convert them to float\n",
    "        min_float = float(min_float_text)\n",
    "        max_float = float(max_float_text)\n",
    "\n",
    "        print(f\"{collection_name}, {skin_name}, {quality}, {min_float}, {max_float}\")\n",
    "        skin_non_stattrak = Skin(skin_name, min_float, max_float, stattrak=False, collection_name=collection_name, quality=quality)\n",
    "        create_skin(skin_non_stattrak)\n",
    "        if stattrak_available:\n",
    "            skin_stattrak = Skin(skin_name, min_float, max_float, stattrak=True, collection_name=collection_name, quality=quality)\n",
    "            create_skin(skin_stattrak)\n",
    "    except TimeoutException:\n",
    "        print(\"I give up...\")\n",
    "    finally:\n",
    "        browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "divSoup = BeautifulSoup(div_html,'html.parser')\n",
    "\n",
    "# Iterate over all <a> tags directly under the div\n",
    "stored_collections = ['2018 Inferno', '2018 Nuke', '2021 Dust 2', '2021 Mirage', '2021 Train', '2021 Vertigo', 'Alpha']\n",
    "for a_tag in divSoup.find_all('a', class_='a_subcategory'):\n",
    "    # Find the <p> tag inside the current <a> tag\n",
    "    p_tag = a_tag.find('p', class_='p_subcategory_weapon')\n",
    "    if p_tag:\n",
    "        # Print the text inside the <p> tag and the href of the <a> tag\n",
    "        collection = p_tag.text\n",
    "        if collection not in stored_collections:\n",
    "            collection_url = a_tag['href']\n",
    "            parse_collection(collection, collection_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
